{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23746603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from evaluate import load\n",
    "from datasets import Dataset\n",
    "from transformers import Trainer\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments\n",
    "from transformers import DataCollatorWithPadding\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff96ea88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"News-Classification-Dataset/barely-true-cleaned.csv\")\n",
    "df2 = pd.read_csv(\"News-Classification-Dataset/false-cleaned.csv\")\n",
    "df3 = pd.read_csv(\"News-Classification-Dataset/half-true-cleaned.csv\")\n",
    "df4 = pd.read_csv(\"News-Classification-Dataset/mostly-true-cleaned.csv\")\n",
    "df5 = pd.read_csv(\"News-Classification-Dataset/pants-fire-cleaned.csv\")\n",
    "df6 = pd.read_csv(\"News-Classification-Dataset/true-cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837d6545",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3, df4, df5, df6], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae0e810",
   "metadata": {},
   "source": [
    "## Checking the data for imbalances\n",
    "\n",
    "- Class imbalances can be a serious problem for machine learning models.\n",
    "\n",
    "If there are class imbalances, the model may not learn to predict the minority class well. This can be solves using \n",
    "- oversampling\n",
    "- Weighted classes\n",
    "- SMOTE (Synthetic Minority Over-sampling Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6db49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic overview of the dataset\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb9b73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(missing_values[missing_values > 0])  # Only show columns with missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d08826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class distribution \n",
    "class_count = df['Label'].value_counts()\n",
    "print(\"\\nClass count (%):\")\n",
    "print(class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6549cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.sample(frac=0.8, random_state=42)\n",
    "df_eval = df.drop(df_train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51c989b",
   "metadata": {},
   "source": [
    "## Label Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d425ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_id = {label: id for id, label in enumerate(df['Label'].unique())}\n",
    "print(\"\\nLabel to ID mapping: \", end=\"\")\n",
    "print(label_to_id)\n",
    "\n",
    "id_to_label = {id: label for label, id in label_to_id.items()}\n",
    "print(\"\\nID to Label mapping: \", end=\"\")\n",
    "print(id_to_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9625f9",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "- Padding and Truncation are very crucial for the model to work properly.\n",
    "- Padding is used to make all sequences the same length.\n",
    "- Truncation is used to cut off sequences that are too long.\n",
    "- The tokenizer will automatically pad and truncate the sequences to the maximum length of the model.\n",
    "- The tokenizer will also convert the text to input IDs and attention masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acd6f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "## Sample text and tokenization\n",
    "sample_text = df['Statement'].iloc[0]\n",
    "print(\"\\nSample text:\")\n",
    "print(sample_text)\n",
    "print(\"\\nTokenized sample text:\")\n",
    "sample_tokens = tokenizer(sample_text, truncation=True, padding='max_length', max_length=128)\n",
    "print(sample_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef146dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokenized_train_dict = tokenizer(list(df_train['Statement']), truncation=True, padding='max_length', max_length=128)\n",
    "df_tokenized_eval_dict = tokenizer(list(df_eval['Statement']), truncation=True, padding='max_length', max_length=128)\n",
    "\n",
    "df_tokenized_train_dict['labels'] = [label_to_id[label] for label in df_train['Label'].tolist()]\n",
    "df_tokenized_eval_dict['labels'] = [label_to_id[label] for label in df_eval['Label'].tolist()]\n",
    "\n",
    "print(df_tokenized_train_dict.keys())\n",
    "for key, value in df_tokenized_train_dict.items():\n",
    "    print(f\"{key}: {type(value[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a96a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokenized_train = Dataset.from_dict(df_tokenized_train_dict)\n",
    "df_tokenized_eval = Dataset.from_dict(df_tokenized_eval_dict)\n",
    "\n",
    "print(df_tokenized_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0219b8",
   "metadata": {},
   "source": [
    "## Model\n",
    "- The model is a standard BERT model that is pre-trained.\n",
    "\n",
    "Choosing the right model is very crucial\n",
    "- distilbert is used for systems for low latency and high throughput.\n",
    "- bert-base-uncased is used for systems that require high accuracy and can afford to run slower.\n",
    "- bert-large-uncased is used for systems that require very high accuracy and can afford to run slower.\n",
    "\n",
    "The performace difference between the models depends on the task and the dataset. But in general, the larger the model, the better the performance.\n",
    "- But distilbert usually performs within a few percentage points of bert-base-uncased and is much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae547460",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(label_to_id))\n",
    "\n",
    "print(model.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a797f8c1",
   "metadata": {},
   "source": [
    "## Freezing layers\n",
    "\n",
    "- Freezing layers is a technique used to prevent the model from updating the weights of certain layers during training.\n",
    "- This is useful when you want to fine-tune a pre-trained model on a new task.\n",
    "- Freezing layers can help to prevent overfitting and speed up training.\n",
    "\n",
    "Generally a good approach would be:\n",
    "- To freeze all the embedding layers and the first few layers of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf7dc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the model architecture to see layers\n",
    "for name, param in model.named_parameters():\n",
    "    print(name)\n",
    "\n",
    "num_layers = len(model.bert.encoder.layer)\n",
    "print(f\"\\nNumber of layers in BERT encoder: {num_layers}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fff5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers_to_freeze = 6  \n",
    "\n",
    "# Freeze embeddings\n",
    "for param in model.bert.embeddings.parameters():\n",
    "    param.requires_grad = False\n",
    "print(f\"Embeddings frozen\")\n",
    "\n",
    "# Freeze the first N encoder layers\n",
    "for i in range(num_layers_to_freeze):\n",
    "    for param in model.bert.encoder.layer[i].parameters():\n",
    "        param.requires_grad = False\n",
    "    print(f\"Layer {i} frozen\")\n",
    "\n",
    "frozen_params = sum(p.numel() for p in model.parameters() if not p.requires_grad)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Frozen parameters: {frozen_params:,} / {total_params:,} ({100 * frozen_params / total_params:.2f}%)\")\n",
    "print(f\"Trainable parameters: {total_params - frozen_params:,} / {total_params:,} ({100 * (total_params - frozen_params) / total_params:.2f}%)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a89f9b5",
   "metadata": {},
   "source": [
    "## Extending BERT architecture (if adventurous)\n",
    "\n",
    "```python\n",
    "class CustomBERTModel(nn.Module):\n",
    "    def __init__(self, pretrained_model_name, num_labels):\n",
    "        super(CustomBERTModel, self).__init__()\n",
    "        self.bert = AutoModelForSequenceClassification.from_pretrained(pretrained_model_name, num_labels=num_labels)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = self.dropout(output[1])  # Applying dropout\n",
    "        logits = self.fc(pooled_output)  # Adding a fully connected layer\n",
    "        return logits\n",
    "\n",
    "# Initialize the custom model\n",
    "custom_model = CustomBERTModel(\"bert-base-uncased\", num_labels=3)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1647ad9e",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "We need to define the training paramaters for the model such as:\n",
    "\n",
    "Basic Configuration\n",
    "- output_dir: directory to save the model checkpoints\n",
    "- logging_dir: directory to save the logs\n",
    "- logging_steps: number of steps to log the training progress\n",
    "\n",
    "Traning Schedule\n",
    "- num_train_epochs: number of epochs to train the model\n",
    "- learning_rate: learning rate for the optimizer\n",
    "- weight_decay: Applying L2 regularization to the optimizer\n",
    "\n",
    "Batch Size\n",
    "- per_device_train_batch_size: batch size for training\n",
    "- per_device_eval_batch_size: batch size for evaluation\n",
    "\n",
    "Evaluation & Saving\n",
    "- evalutation_strategy: strategy to evaluate the model\n",
    "- save_strategy: strategy to save the model\n",
    "- save_total_limit: maximum number of checkpoints to save\n",
    "- load_best_model_at_end: whether to load the best model at the end of training\n",
    "\n",
    "Performance Optimization\n",
    "- fp16: whether to use mixed precision training (requires NVIDIA GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b4af85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330fb109",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",    \n",
    "    logging_dir=\"./logs\",            \n",
    "    logging_steps=100, \n",
    "    num_train_epochs=3, \n",
    "    learning_rate=5e-5,  \n",
    "    weight_decay=0.01,   \n",
    "    per_device_train_batch_size=16,  \n",
    "    per_device_eval_batch_size=16,              \n",
    "    evaluation_strategy=\"epoch\",     \n",
    "    save_strategy=\"epoch\",                                           \n",
    "    save_total_limit=2,              \n",
    "    load_best_model_at_end=True,                 \n",
    "    fp16 = True if torch.cuda.is_available() else False,                        \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ac36d7",
   "metadata": {},
   "source": [
    "## Defining metric for evaluation\n",
    "\n",
    "- Usualy accuracy is used as the metric for evaluation.\n",
    "- However, for imbalanced datasets, it is better to use F1 score, precision, and recall.\n",
    "\n",
    "What are logits?\n",
    "- Logits are the raw, unnormalized scores output by the model before applying the softmax function.\n",
    "- They represent the model's confidence in each class.\n",
    "- The softmax function is applied to the logits to convert them into probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bde0142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    f1 = f1_score(labels, predictions, average=\"weighted\")  # or \"macro\", \"micro\", \"binary\"\n",
    "    return {\"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47ae373",
   "metadata": {},
   "source": [
    "## Data Collator\n",
    "\n",
    "The DataCollatorWithPadding from Hugging Face Transformers automatically pads input sequences to the same length within a batch during training or evaluation.\n",
    "\n",
    "This is important because:\n",
    "\n",
    "- Transformer models (like BERT, RoBERTa) expect inputs to be of the same length.\n",
    "- But real-world text samples usually have variable lengths.\n",
    "- Padding too early (globally) wastes memory; padding just-in-time per batch is more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca83e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d817bfd0",
   "metadata": {},
   "source": [
    "## Setting up the Trainer\n",
    "\n",
    "The arguments for the Trainer class are crucial for training the model effectively. Here are some key arguments:\n",
    "- model: The model to be trained.\n",
    "- args: Training arguments that define the training configuration. (usually defined in TrainingArguments)\n",
    "- train_dataset: The dataset to be used for training. The structure of the dataset should be a dictionary with 'input_ids', 'attention_mask', and 'labels'.\n",
    "- eval_dataset: The dataset to be used for evaluation. It should have the same structure as the training dataset.\n",
    "- compute_metrics: A function to compute metrics during evaluation. It should take the predictions and labels as input and return a dictionary of metrics.\n",
    "\n",
    "Structure of the dataset:\n",
    "\n",
    "```python\n",
    "{\n",
    "    'input_ids': [list of input IDs],\n",
    "    'attention_mask': [list of attention masks],\n",
    "    'labels': [list of labels]\n",
    "}\n",
    "```\n",
    "\n",
    "This must be a dataset object, use the following code to convert a pandas dataframe to a dataset object:\n",
    "\n",
    "```python\n",
    "from datasets import Dataset    \n",
    "Dataset.from_dict(...)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efbd0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check the structure of the tokenized dataset\n",
    "print(df_tokenized_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b795831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                        \n",
    "    args=training_args,                 \n",
    "    train_dataset=df_tokenized_train,\n",
    "    eval_dataset=df_tokenized_eval,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,        \n",
    "    compute_metrics=compute_metrics     \n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4c7690",
   "metadata": {},
   "source": [
    "## Other Important Arguments for Trainer\n",
    "\n",
    "#### Gradient Accumulation\n",
    "- Gradient accumulation is a technique used to simulate a larger batch size by accumulating gradients over multiple steps before performing an optimization step.\n",
    "- This is useful when the model is too large to fit into memory with a large batch size.\n",
    "\n",
    "``` python\n",
    "training_args.gradient_accumulation_steps = 4\n",
    "``` \n",
    "\n",
    "#### Early Stopping\n",
    "- Early stopping is a technique used to stop training when the model's performance on the validation set stops improving.\n",
    "- This helps to prevent overfitting and saves training time.\n",
    "``` python\n",
    "from transformers import EarlyStoppingCallback\n",
    "training_args.load_best_model_at_end = True\n",
    "training_args.metric_for_best_model = \"f1\"\n",
    "training_args.greater_is_better = True\n",
    "trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=3))\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209399db",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16c4a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e82e10",
   "metadata": {},
   "source": [
    "## Displaying the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c361d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "predictions = trainer.predict(df_tokenized_eval)\n",
    "predicted_labels = predictions.predictions.argmax(axis=-1)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(df_tokenized_eval[\"labels\"], predicted_labels))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(df_tokenized_eval[\"labels\"], predicted_labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(label_to_id.keys()))\n",
    "disp.plot(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2f19a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5478e666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a620ed5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
